{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enron - Detecting Financial Fraud\n",
    "\n",
    "The goal of this project is to analyze s and extract the key persons of interest for the company \"Enron\" using machine learning. It is interesting to analyze this set as the emails are publickly availbale and there was company wide involvement in accounting scandals and financial fraud which eventually led to its declaration of bankruptcy and liquadation in Dec 2001. This also led to the conviction of many officers from upper management, including the CEO and the COO.\n",
    "\n",
    "Enron as a company was primarily involved in energy, commodities and services in America. At the end of 2001, it was revealed that its reported financial condition was sustained by institutionalized, systematic, and creatively planned accounting fraud, known since as the Enron scandal. Enron has since become a well-known example of willful corporate fraud and corruption. The scandal also brought into question the accounting practices and activities of many corporations in the United States and was a factor in the enactment of the Sarbanes–Oxley Act of 2002. The scandal also affected the greater business world by causing the dissolution of the Arthur Andersen accounting firm.\n",
    "\n",
    "Machine learning will help us locate and collect the features that are common between the points of interest and also help in prediciting based on those features which people could be the persons of interest (POIs) in relation to the ones that have similar values of those features. This along with the financial information and the email data will help us predict the primary people of interest. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives of this project \n",
    "\n",
    "#### 1.What is the goal of this project? \n",
    "It is to show how machine learning is useful in trying to accomplish persons of interest in the Enron scandal. In this project, we will be building a person of interest identifier based on financial and email data made public as a result of the Enron scandal. A list of people who can be compared to for finding the precision of person of interest detection is provided. This list chould be used for precision / accuracy comparision. \n",
    "The resources needed gives a list of started codes and data to begin with.\n",
    "\n",
    "#### 2.What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not?In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importances of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values.  [relevant rubric items: “create new features”, “intelligently select features”, “properly scale features”]\n",
    "\n",
    "This is done in the file poi_id.py. It many functions that allow one to look at the various features available in the data set, clean it, perform feature selection etc and finally be able to predict the POIs. The file tester.py is used to cross check the results the code actually produces for transparency which help evaluating. \n",
    "Various methods were adopted for feature selection please see below.\n",
    "\n",
    "#### 3.What algorithm did you end up using? What other one(s) did you try? How did model performance differ between algorithms?  [relevant rubric item: “pick an algorithm”]\n",
    "\n",
    "The following were tried.\n",
    "\n",
    "    a.classifyNB() - Naive bayes classifier\n",
    "    b.classifyRF() - Random Forests classifier\n",
    "    c.classifyAB() - Adaboost classifier\n",
    "    d.classifyDT() - Decision tree classifier\n",
    "    e.classifySVM() - Support Vector classifier.\n",
    "\n",
    "\n",
    "I was able to get a good precision on Randomforests but unable to use it for testing purposes in tester.py.\n",
    "Decision trees (post tuning) and Naive Bayes (no tuning) gave best results on precision, recall and accuracy.\n",
    "My final choice was a decision tree.\n",
    "\n",
    "#### 4.What does it mean to tune the parameters of an algorithm, and what can happen if you don’t do this well?  How did you tune the parameters of your particular algorithm? What parameters did you tune? .  [relevant rubric items: “discuss parameter tuning”, “tune the algorithm”]\n",
    "\n",
    "Since I used decision trees to finally and the parameter's it allows for tuning are the following:\n",
    "\n",
    "                                     (criterion='gini', splitter='best', \\\n",
    "                                      max_depth=None, min_samples_split=2, \\\n",
    "                                      min_samples_leaf=1, min_weight_fraction_leaf=0.0,\\\n",
    "                                      max_features=None, random_state=8, \\\n",
    "                                      max_leaf_nodes=None, min_impurity_split=1e-07,\\\n",
    "                                      class_weight=None, presort=False)\n",
    "\n",
    "here I tried tuning various parameters such as criterion, min_samples_split and max_features\n",
    "notice random_state was changed to an int so that variable results are avoided on each trial\n",
    "\n",
    "#### 5.What is validation, and what’s a classic mistake you can make if you do it wrong? How did you validate your analysis?  [relevant rubric items: “discuss validation”, “validation strategy”]\n",
    "\n",
    "A random split into training and test sets can be quickly computed with the train_test_split function as such.\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    \n",
    "  This split was perfomed and the following procedure was applied \n",
    "    \n",
    "    clf.fit(features_train, labels_train)\n",
    " A fit was perfomed on the features_train and the labels_train using the training data.\n",
    "    \n",
    "    pred = clf.predict(features_test)\n",
    " Prediction were perfomed on the features_test, test data\n",
    "    \n",
    "    \n",
    "\n",
    "#### 6.Give at least 2 evaluation metrics and your average performance for each of them.  Explain an interpretation of your metrics that says something human-understandable about your algorithm’s performance. [relevant rubric item: “usage of evaluation metrics”]\n",
    "\n",
    "        acc = accuracy_score(labels_test, pred)\n",
    " Accuracy was predicted on the predicted labels and the labels_test in the test data.\n",
    "    \n",
    "        pres = precision_score(labels_test, pred)\n",
    " Pres was predicted on the predicted labels and the labels_test in the test data.\n",
    " \n",
    "     DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "             max_features=None, max_leaf_nodes=None,\n",
    "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "             presort=False, random_state=8, splitter='best')\n",
    "             Accuracy: 0.82114       Precision: 0.37562      Recall: 0.38050 F1: 0.37804     F2: 0.37951\n",
    "             Total predictions: 14000        True positives:  761    False positiv\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Selecting features:\n",
    "\n",
    "\n",
    "Using explore_enron_data.py the following information was identified from the final_project_dataset.\n",
    "\n",
    "1. There are 146 names in the list of data set.\n",
    "2. There are 21 attributes for each name : \n",
    "    ['salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'email_address', 'from_poi_to_this_person']\n",
    "    \n",
    "3. Here 18 names are marked as persons on interest.\n",
    "4. Of the people who have stocks, total stock value has a max and a min of (311764000, 3285) respectively.\n",
    "5. Of the people who are salaried the max and min salaries are (26704229, 477) respectivly.\n",
    "6. Out of the the features the following are interesting to look at from a first look : \n",
    "\n",
    "    a. salary , b. total_stock_options, c. bonus, d. from_this_person_to_poi, e. poi, f. from_poi_to_this_person,\n",
    "    g. expenses etc.\n",
    "\n",
    "7. Doing some analysis on these : \n",
    "\n",
    "    a. A correlation table was created for all the features in R \"enron_file.rmd\"\n",
    "    b. This file also creates two cleaned CSVs that are used for feature selection exercise.\n",
    "   \n",
    "8. From this correlations table below we see that salary, total_payments, exercised_stock_options , bonus ,total_stock_value, director_fees, long_term_incentive are strongly positively correlated and salary, deferred_income are strongly negatively correlated. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                 salary  to_messages deferral_payments total_payments exercised_stock_options\n",
    "salary                     1.0000000000 -0.010072139       0.964071471    0.956377184              0.98658801\n",
    "to_messages               -0.0100721389  1.000000000      -0.009674288    0.021410550             -0.02897966\n",
    "deferral_payments          0.9640714711 -0.009674288       1.000000000    0.921956156              0.95166346\n",
    "total_payments             0.9563771837  0.021410550       0.921956156    1.000000000              0.96508671\n",
    "exercised_stock_options    0.9865880146 -0.028979656       0.951663465    0.965086714              1.00000000\n",
    "bonus                      0.9933110819  0.033652765       0.958108631    0.962046810              0.98337429\n",
    "restricted_stock           0.9878835817 -0.015274727       0.950034586    0.965397994              0.98615449\n",
    "shared_receipt_with_poi   -0.0079035629  0.882062494       0.005958577    0.032152459             -0.02950108\n",
    "restricted_stock_deferred -0.4450349824 -0.004478446      -0.430441448   -0.378268396             -0.43267296\n",
    "total_stock_value          0.9894865361 -0.024682588       0.953548119    0.968210996              0.99879383\n",
    "expenses                   0.9939871823 -0.019883533       0.956175331    0.945323616              0.98017342\n",
    "loan_advances              0.7361178323  0.048216067       0.690475066    0.895695967              0.77539887\n",
    "from_messages             -0.0077204501  0.508814271      -0.011847391   -0.016512929             -0.02450544\n",
    "other                      0.9632793254 -0.011148402       0.946820414    0.982825157              0.96696424\n",
    "from_this_person_to_poi   -0.0068828927  0.605984265      -0.023737120   -0.003703825             -0.02444243\n",
    "poi                       -0.0006265269  0.111261589      -0.040408579    0.049776802              0.04031499\n",
    "director_fees              0.9544945009 -0.087941456       0.921844004    0.910305494              0.94353303\n",
    "deferred_income           -0.9710517730  0.013093481      -0.968219094   -0.923116722             -0.96359861\n",
    "long_term_incentive        0.9901724618 -0.012270749       0.953707616    0.960402651              0.98139500\n",
    "from_poi_to_this_person   -0.0065252415  0.619994085       0.018061379    0.029829644             -0.01912451\n",
    "\n",
    "\n",
    "\n",
    "                                 bonus restricted_stock shared_receipt_with_poi restricted_stock_deferred\n",
    "salary                     0.993311082       0.98788358            -0.007903563              -0.445034982\n",
    "to_messages                0.033652765      -0.01527473             0.882062494              -0.004478446\n",
    "deferral_payments          0.958108631       0.95003459             0.005958577              -0.430441448\n",
    "total_payments             0.962046810       0.96539799             0.032152459              -0.378268396\n",
    "exercised_stock_options    0.983374292       0.98615449            -0.029501077              -0.432672962\n",
    "bonus                      1.000000000       0.98344674             0.047518123              -0.440520280\n",
    "restricted_stock           0.983446742       1.00000000            -0.019283273              -0.456229181\n",
    "shared_receipt_with_poi    0.047518123      -0.01928327             1.000000000               0.005202391\n",
    "restricted_stock_deferred -0.440520280      -0.45622918             0.005202391               1.000000000\n",
    "total_stock_value          0.986016441       0.99306005            -0.026169099              -0.440206357\n",
    "expenses                   0.987001190       0.98111464            -0.023309401              -0.443636754\n",
    "loan_advances              0.752378491       0.77737385             0.057610800              -0.317392139\n",
    "from_messages              0.006055219      -0.01603798             0.302726689              -0.010899427\n",
    "other                      0.959031981       0.97167348             0.003783105              -0.420779662\n",
    "from_this_person_to_poi    0.042789182      -0.01394585             0.525601288              -0.008650658\n",
    "poi                        0.023754969       0.01520883             0.243312982              -0.005362459\n",
    "director_fees              0.947248521       0.94038245            -0.102634380              -0.343280346\n",
    "deferred_income           -0.969017217      -0.95686502            -0.008038932               0.436273674\n",
    "long_term_incentive        0.987034238       0.97952734            -0.005584562              -0.439291876\n",
    "from_poi_to_this_person    0.054515307      -0.01897855             0.734200226              -0.022683017\n",
    "\n",
    "                          total_stock_value     expenses loan_advances from_messages        other\n",
    "salary                           0.98948654  0.993987182    0.73611783  -0.007720450  0.963279325\n",
    "to_messages                     -0.02468259 -0.019883533    0.04821607   0.508814271 -0.011148402\n",
    "deferral_payments                0.95354812  0.956175331    0.69047507  -0.011847391  0.946820414\n",
    "total_payments                   0.96821100  0.945323616    0.89569597  -0.016512929  0.982825157\n",
    "exercised_stock_options          0.99879383  0.980173421    0.77539887  -0.024505437  0.966964245\n",
    "bonus                            0.98601644  0.987001190    0.75237849   0.006055219  0.959031981\n",
    "restricted_stock                 0.99306005  0.981114641    0.77737385  -0.016037984  0.971673480\n",
    "shared_receipt_with_poi         -0.02616910 -0.023309401    0.05761080   0.302726689  0.003783105\n",
    "restricted_stock_deferred       -0.44020636 -0.443636754   -0.31739214  -0.010899427 -0.420779662\n",
    "total_stock_value                1.00000000  0.982885449    0.77921715  -0.022204355  0.971330083\n",
    "expenses                         0.98288545  1.000000000    0.71983429  -0.004280533  0.951529277\n",
    "loan_advances                    0.77921715  0.719834294    1.00000000  -0.028359278  0.842760505\n",
    "from_messages                   -0.02220436 -0.004280533   -0.02835928   1.000000000 -0.036341757\n",
    "other                            0.97133008  0.951529277    0.84276051  -0.036341757  1.000000000\n",
    "from_this_person_to_poi         -0.02124827 -0.011225352   -0.02488482   0.609987734 -0.039366056\n",
    "poi                              0.03446248 -0.009456427    0.13178914  -0.032633400  0.022232561\n",
    "director_fees                    0.94486220  0.956347765    0.68503832  -0.040692094  0.912887195\n",
    "deferred_income                 -0.96395674 -0.963304082   -0.69608443   0.016163693 -0.941804530\n",
    "long_term_incentive              0.98346162  0.982047147    0.75204015  -0.010942170  0.966168888\n",
    "from_poi_to_this_person         -0.01883314 -0.027190330    0.03963416   0.254959795  0.007797323\n",
    "\n",
    "                          from_this_person_to_poi           poi director_fees deferred_income long_term_incentive\n",
    "salary                               -0.006882893 -0.0006265269    0.95449450    -0.971051773         0.990172462\n",
    "to_messages                           0.605984265  0.1112615893   -0.08794146     0.013093481        -0.012270749\n",
    "deferral_payments                    -0.023737120 -0.0404085788    0.92184400    -0.968219094         0.953707616\n",
    "total_payments                       -0.003703825  0.0497768025    0.91030549    -0.923116722         0.960402651\n",
    "exercised_stock_options              -0.024442433  0.0403149911    0.94353303    -0.963598610         0.981394999\n",
    "bonus                                 0.042789182  0.0237549686    0.94724852    -0.969017217         0.987034238\n",
    "restricted_stock                     -0.013945854  0.0152088272    0.94038245    -0.956865016         0.979527342\n",
    "shared_receipt_with_poi               0.525601288  0.2433129816   -0.10263438    -0.008038932        -0.005584562\n",
    "restricted_stock_deferred            -0.008650658 -0.0053624590   -0.34328035     0.436273674        -0.439291876\n",
    "total_stock_value                    -0.021248270  0.0344624846    0.94486220    -0.963956739         0.983461622\n",
    "expenses                             -0.011225352 -0.0094564270    0.95634777    -0.963304082         0.982047147\n",
    "loan_advances                        -0.024884820  0.1317891383    0.68503832    -0.696084428         0.752040153\n",
    "from_messages                         0.609987734 -0.0326334002   -0.04069209     0.016163693        -0.010942170\n",
    "other                                -0.039366056  0.0222325607    0.91288719    -0.941804530         0.966168888\n",
    "from_this_person_to_poi               1.000000000  0.1310080926   -0.05022345     0.023262256         0.001461896\n",
    "poi                                   0.131008093  1.0000000000   -0.06138801    -0.039544261         0.012886075\n",
    "director_fees                        -0.050223454 -0.0613880127    1.00000000    -0.928889823         0.944551538\n",
    "deferred_income                       0.023262256 -0.0395442615   -0.92888982     1.000000000        -0.966250350\n",
    "long_term_incentive                   0.001461896  0.0128860748    0.94455154    -0.966250350         1.000000000\n",
    "from_poi_to_this_person               0.498936149  0.1926209739   -0.08496750    -0.007899908         0.002830121\n",
    "\n",
    "                          from_poi_to_this_person\n",
    "salary                               -0.006525242\n",
    "to_messages                           0.619994085\n",
    "deferral_payments                     0.018061379\n",
    "total_payments                        0.029829644\n",
    "exercised_stock_options              -0.019124514\n",
    "bonus                                 0.054515307\n",
    "restricted_stock                     -0.018978549\n",
    "shared_receipt_with_poi               0.734200226\n",
    "restricted_stock_deferred            -0.022683017\n",
    "total_stock_value                    -0.018833141\n",
    "expenses                             -0.027190330\n",
    "loan_advances                         0.039634159\n",
    "from_messages                         0.254959795\n",
    "other                                 0.007797323\n",
    "from_this_person_to_poi               0.498936149\n",
    "poi                                   0.192620974\n",
    "director_fees                        -0.084967503\n",
    "deferred_income                      -0.007899908\n",
    "long_term_incentive                   0.002830121\n",
    "from_poi_to_this_person               1.000000000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Feature selection using three methods\n",
    "\n",
    "a. FeatureRFE() - recursive feature elimination using a random forests classfier says we should use bonus, total         _stock_value, expenses, it also says we should use other but we can ignore this for now from intuition.\n",
    "    \n",
    "b. FeatureETC() - extra method learnt for feature extraction using bagged trees called the extra trees classifier - the results from feature RFE selection recommended using: exercised stock value, total_stock_value, expenses since total and exercised are highly correlated it makese sense to use only one. total_stock_values and of course expenses. \n",
    "      \n",
    "c. Correlations - the table helped select the most valuable features with lower values of cross-correlation like  expenses, total_stock_value, bonus\n",
    "    \n",
    "The results from feature selection process (manual and automated) recommended using 4 features in combination,\n",
    "a. salary, b. bonus, c. total_stock_value, d. expenses  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Removing outliers\n",
    "First the task was to view all the outliers\n",
    "this was done using the following \n",
    "a. plotSalaryStock(data1) - plotting salary Vs Total stock value\n",
    "b. plotSalaryExpense(data1) - plotting salary Vs receipt with poi\n",
    "c. plotStockExpense(data1) - plotting stock vs receipt with poi\n",
    "d. plotSalaryBonus(data1) - plotting salary vs bonus\n",
    "\n",
    "\n",
    "Outliers were removed using three functions\n",
    "a.salaryOut()- removing salary outliers\n",
    "b.totalStockValueOut() - removing total_stock_value outliers\n",
    "c.bonusOut() - removing bonus outliers\n",
    "d.expenseOut() - removing the expense outliers.\n",
    " \n",
    " \n",
    "The plots were replotted after removal of outliers using the plotting functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creating new feature(s)\n",
    "\n",
    "\n",
    "Building feature for realtive importance\n",
    "Total number of \"to emails\" to this person - shared with poi - sent by poi to this person.\n",
    "The lower this number greater the relative importance.\n",
    "\n",
    "This was done in the newFeature().\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extracting features and labels from dataset for local testing\n",
    "\n",
    "Features were now extracted and stored for local testing using the featureFormat()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Trying variety of classifiers\n",
    "\n",
    "Many classifiers were tried : \n",
    "a.classifyNB() - Naive bayes classifier\n",
    "b.classifyRF() - Random Forests classifier\n",
    "c.classifyAB() - Adaboost classifier\n",
    "d.classifyDT() - Decision tree classifier\n",
    "e.classifySVM() - Support vector machine classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Tuning the classifier \n",
    "to achieve better than .3 precision and recall \n",
    "\n",
    "Check the tester.py script in the final project\n",
    "\n",
    "Decision tree classifier was tuned and used for final predicition using the following parameters:\n",
    "\n",
    "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "             max_features=None, max_leaf_nodes=None,\n",
    "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "             presort=False, random_state=None, splitter='best')\n",
    "         Accuracy: 0.80729       Precision: 0.33205      Recall: 0.34500 F1: 0.33840     F2: 0.34233\n",
    "         Total predictions: 14000        True positives:  690    False positives: 1388   False negatives: 1310   True negatives: 10612\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Dumping the classifier, dataset, and features_list \n",
    "\n",
    "the classifier was dumped using the following\n",
    "\n",
    "clf = classifyDT()\n",
    "my_dataset = my_dataset\n",
    "features_list = features_list\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
