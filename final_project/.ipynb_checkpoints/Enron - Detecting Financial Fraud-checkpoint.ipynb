{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enron - Detecting Financial Fraud\n",
    "\n",
    "The goal of this project is to analyze s and extract the key persons of interest for the company \"Enron\" using machine learning. It is interesting to analyze this set as the emails are publickly availbale and there was company wide involvement in accounting scandals and financial fraud which eventually led to its declaration of bankruptcy and liquadation in Dec 2001. This also led to the conviction of many officers from upper management, including the CEO and the COO.\n",
    "\n",
    "Enron as a company was primarily involved in energy, commodities and services in America. At the end of 2001, it was revealed that its reported financial condition was sustained by institutionalized, systematic, and creatively planned accounting fraud, known since as the Enron scandal. Enron has since become a well-known example of willful corporate fraud and corruption. The scandal also brought into question the accounting practices and activities of many corporations in the United States and was a factor in the enactment of the Sarbanes–Oxley Act of 2002. The scandal also affected the greater business world by causing the dissolution of the Arthur Andersen accounting firm.\n",
    "\n",
    "Machine learning will help us locate and collect the features that are common between the points of interest and also help in prediciting based on those features which people could be the persons of interest (POIs) in relation to the ones that have similar values of those features. This along with the financial information and the email data will help us predict the primary people of interest. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives of this project \n",
    "\n",
    "#### 1.What is the goal of this project? \n",
    "It is to show how machine learning is useful in trying to accomplish persons of interest in the Enron scandal. In this project, we will be building a person of interest identifier based on financial and email data made public as a result of the Enron scandal. A list of people who can be compared to for finding the precision of person of interest detection is provided. This list chould be used for precision / accuracy comparision. \n",
    "The resources needed gives a list of started codes and data to begin with.\n",
    "\n",
    "#### 2.What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not?In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importances of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values.  [relevant rubric items: “create new features”, “intelligently select features”, “properly scale features”]\n",
    "\n",
    "This is done in the file poi_id.py. It many functions that allow one to look at the various features available in the data set, clean it, perform feature selection etc and finally be able to predict the POIs. The file tester.py is used to cross check the results the code actually produces for transparency which help evaluating. \n",
    "Various methods were adopted for feature selection please see below.\n",
    "\n",
    "#### 3.What algorithm did you end up using? What other one(s) did you try? How did model performance differ between algorithms?  [relevant rubric item: “pick an algorithm”]\n",
    "\n",
    "The following were tried.\n",
    "\n",
    "    a.classifyNB() - Naive bayes classifier\n",
    "    b.classifyRF() - Random Forests classifier\n",
    "    c.classifyAB() - Adaboost classifier\n",
    "    d.classifyDT() - Decision tree classifier\n",
    "    e.classifySVM() - Support Vector classifier.\n",
    "\n",
    "\n",
    "I was able to get a good precision on Randomforests but unable to use it for testing purposes in tester.py.\n",
    "Decision trees (post tuning) and Naive Bayes (no tuning) gave best results on precision, recall and accuracy.\n",
    "My final choice was a decision tree.\n",
    "\n",
    "#### 4.What does it mean to tune the parameters of an algorithm, and what can happen if you don’t do this well?  How did you tune the parameters of your particular algorithm? What parameters did you tune? .  [relevant rubric items: “discuss parameter tuning”, “tune the algorithm”]\n",
    "\n",
    "Since I used decision trees to finally and the parameter's it allows for tuning are the following:\n",
    "\n",
    "                                     (criterion='gini', splitter='best', \\\n",
    "                                      max_depth=None, min_samples_split=2, \\\n",
    "                                      min_samples_leaf=1, min_weight_fraction_leaf=0.0,\\\n",
    "                                      max_features=None, random_state=8, \\\n",
    "                                      max_leaf_nodes=None, min_impurity_split=1e-07,\\\n",
    "                                      class_weight=None, presort=False)\n",
    "\n",
    "here I tried tuning various parameters such as criterion, min_samples_split and max_features\n",
    "notice random_state was changed to an int so that variable results are avoided on each trial\n",
    "\n",
    "#### 5.What is validation, and what’s a classic mistake you can make if you do it wrong? How did you validate your analysis?  [relevant rubric items: “discuss validation”, “validation strategy”]\n",
    "\n",
    "A random split into training and test sets can be quickly computed with the train_test_split function as such.\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    \n",
    "  This split was perfomed and the following procedure was applied \n",
    "    \n",
    "    clf.fit(features_train, labels_train)\n",
    " A fit was perfomed on the features_train and the labels_train using the training data.\n",
    "    \n",
    "    pred = clf.predict(features_test)\n",
    " Prediction were perfomed on the features_test, test data\n",
    "    \n",
    "    \n",
    "\n",
    "#### 6.Give at least 2 evaluation metrics and your average performance for each of them.  Explain an interpretation of your metrics that says something human-understandable about your algorithm’s performance. [relevant rubric item: “usage of evaluation metrics”]\n",
    "\n",
    "        acc = accuracy_score(labels_test, pred)\n",
    " Accuracy was predicted on the predicted labels and the labels_test in the test data.\n",
    "    \n",
    "        pres = precision_score(labels_test, pred)\n",
    " Pres was predicted on the predicted labels and the labels_test in the test data.\n",
    " \n",
    "     DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "             max_features=None, max_leaf_nodes=None,\n",
    "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "             presort=False, random_state=8, splitter='best')\n",
    "             Accuracy: 0.82114       Precision: 0.37562      Recall: 0.38050 F1: 0.37804     F2: 0.37951\n",
    "             Total predictions: 14000        True positives:  761    False positiv\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Selecting features:\n",
    "\n",
    "\n",
    "Using explore_enron_data.py the following information was identified from the final_project_dataset.\n",
    "\n",
    "1. There are 146 names in the list of data set.\n",
    "2. There are 21 attributes for each name : \n",
    "    ['salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'email_address', 'from_poi_to_this_person']\n",
    "    \n",
    "3. Here 18 names are marked as persons on interest.\n",
    "4. Of the people who have stocks, total stock value has a max and a min of (311764000, 3285) respectively.\n",
    "5. Of the people who are salaried the max and min salaries are (26704229, 477) respectivly.\n",
    "6. Out of the the features the following are interesting to look at from a first look : \n",
    "\n",
    "    a. salary , b. total_stock_options, c. bonus, d. from_this_person_to_poi, e. poi, f. from_poi_to_this_person,\n",
    "    g. expenses etc.\n",
    "    \n",
    "7. Doing some analysis on these : \n",
    "\n",
    "    a. A correlation table was created for all the features in R \"enron_file.rmd\"\n",
    "    b. This file also creates two cleaned CSVs that are used for feature selection exercise  \n",
    "   \n",
    "8. From this correlations table below we see that salary, total_payments, exercised_stock_options , bonus ,total_stock_value, director_fees, long_term_incentive are strongly positively correlated and salary, deferred_income are strongly negatively correlated. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Summary of the Enron data set.\n",
    "\n",
    "            salary          to_messages      deferral_payments  total_payments      exercised_stock_options\n",
    "     Min.   :     477   Min.   :   57.0   Min.   : -102500   Min.   :      148   Min.   :     3285      \n",
    "     1st Qu.:  211816   1st Qu.:  541.2   1st Qu.:   81573   1st Qu.:   394475   1st Qu.:   527886      \n",
    "     Median :  259996   Median : 1211.0   Median :  227449   Median :  1101393   Median :  1310814      \n",
    "     Mean   :  562194   Mean   : 2073.9   Mean   : 1642674   Mean   :  5081526   Mean   :  5987054      \n",
    "     3rd Qu.:  312117   3rd Qu.: 2634.8   3rd Qu.: 1002672   3rd Qu.:  2093263   3rd Qu.:  2547724      \n",
    "     Max.   :26704229   Max.   :15149.0   Max.   :32083396   Max.   :309886585   Max.   :311764000      \n",
    "     NA's   :51         NA's   :60        NA's   :107        NA's   :21          NA's   :44    \n",
    " \n",
    "         bonus          restricted_stock    shared_receipt_with_poi restricted_stock_deferred total_stock_value  \n",
    "     Min.   :   70000   Min.   : -2604490   Min.   :   2.0          Min.   :-7576788          Min.   :   -44093  \n",
    "     1st Qu.:  431250   1st Qu.:   254018   1st Qu.: 249.8          1st Qu.: -389622          1st Qu.:   494510  \n",
    "     Median :  769375   Median :   451740   Median : 740.5          Median : -146975          Median :  1102872  \n",
    "     Mean   : 2374235   Mean   :  2321741   Mean   :1176.5          Mean   :  166411          Mean   :  6773957  \n",
    "     3rd Qu.: 1200000   3rd Qu.:  1002370   3rd Qu.:1888.2          3rd Qu.:  -75010          3rd Qu.:  2949847  \n",
    "     Max.   :97343619   Max.   :130322299   Max.   :5521.0          Max.   :15456290          Max.   :434509511  \n",
    "     NA's   :64         NA's   :36          NA's   :60              NA's   :128               NA's   :20  \n",
    " \n",
    "    expenses       loan_advances      from_messages          other              from_this_person_to_poi\n",
    "     Min.   :    148   Min.   :  400000   Min.   :   12.00   Min.   :       2   Min.   :  0.00         \n",
    "     1st Qu.:  22614   1st Qu.: 1600000   1st Qu.:   22.75   1st Qu.:    1215   1st Qu.:  1.00         \n",
    "     Median :  46950   Median :41762500   Median :   41.00   Median :   52382   Median :  8.00         \n",
    "     Mean   : 108729   Mean   :41962500   Mean   :  608.79   Mean   :  919065   Mean   : 41.23         \n",
    "     3rd Qu.:  79952   3rd Qu.:82125000   3rd Qu.:  145.50   3rd Qu.:  362096   3rd Qu.: 24.75         \n",
    "     Max.   :5235198   Max.   :83925000   Max.   :14368.00   Max.   :42667589   Max.   :609.00         \n",
    "     NA's   :51        NA's   :142        NA's   :60         NA's   :53         NA's   :60             \n",
    " \n",
    "            poi            director_fees     deferred_income     long_term_incentive email_address     \n",
    "     Length:146         Min.   :   3285   Min.   :-27992891   Min.   :   69223       Length:146        \n",
    "     Class :character   1st Qu.:  98784   1st Qu.:  -694862   1st Qu.:  281250       Class :character  \n",
    "     Mode  :character   Median : 108579   Median :  -159792   Median :  442035       Mode  :character  \n",
    "                        Mean   : 166805   Mean   : -1140475   Mean   : 1470361                      \n",
    "                        3rd Qu.: 113784   3rd Qu.:   -38346   3rd Qu.:  938672                      \n",
    "                        Max.   :1398517   Max.   :     -833   Max.   :48521928                      \n",
    "                        NA's   :129       NA's   :97          NA's   :80                          \n",
    "                    \n",
    "     from_poi_to_this_person\n",
    "     Min.   :  0.00         \n",
    "     1st Qu.: 10.00         \n",
    "     Median : 35.00         \n",
    "     Mean   : 64.90         \n",
    "     3rd Qu.: 72.25         \n",
    "     Max.   :528.00         \n",
    "     NA's   :60    \n",
    " \n",
    " A total of 1323 \"NAs\" were found. \n",
    " Most of the NAs came from the loan_advances and the restricted_stock_deferred features.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                     salary  to_messages deferral_payments total_payments exercised_stock_options\n",
    "    salary                     1.0000000000 -0.010072139       0.964071471    0.956377184              0.98658801\n",
    "    to_messages               -0.0100721389  1.000000000      -0.009674288    0.021410550             -0.02897966\n",
    "    deferral_payments          0.9640714711 -0.009674288       1.000000000    0.921956156              0.95166346\n",
    "    total_payments             0.9563771837  0.021410550       0.921956156    1.000000000              0.96508671\n",
    "    exercised_stock_options    0.9865880146 -0.028979656       0.951663465    0.965086714              1.00000000\n",
    "    bonus                      0.9933110819  0.033652765       0.958108631    0.962046810              0.98337429\n",
    "    restricted_stock           0.9878835817 -0.015274727       0.950034586    0.965397994              0.98615449\n",
    "    shared_receipt_with_poi   -0.0079035629  0.882062494       0.005958577    0.032152459             -0.02950108\n",
    "    restricted_stock_deferred -0.4450349824 -0.004478446      -0.430441448   -0.378268396             -0.43267296\n",
    "    total_stock_value          0.9894865361 -0.024682588       0.953548119    0.968210996              0.99879383\n",
    "    expenses                   0.9939871823 -0.019883533       0.956175331    0.945323616              0.98017342\n",
    "    loan_advances              0.7361178323  0.048216067       0.690475066    0.895695967              0.77539887\n",
    "    from_messages             -0.0077204501  0.508814271      -0.011847391   -0.016512929             -0.02450544\n",
    "    other                      0.9632793254 -0.011148402       0.946820414    0.982825157              0.96696424\n",
    "    from_this_person_to_poi   -0.0068828927  0.605984265      -0.023737120   -0.003703825             -0.02444243\n",
    "    poi                       -0.0006265269  0.111261589      -0.040408579    0.049776802              0.04031499\n",
    "    director_fees              0.9544945009 -0.087941456       0.921844004    0.910305494              0.94353303\n",
    "    deferred_income           -0.9710517730  0.013093481      -0.968219094   -0.923116722             -0.96359861\n",
    "    long_term_incentive        0.9901724618 -0.012270749       0.953707616    0.960402651              0.98139500\n",
    "    from_poi_to_this_person   -0.0065252415  0.619994085       0.018061379    0.029829644             -0.01912451\n",
    "\n",
    "\n",
    "\n",
    "                                     bonus restricted_stock shared_receipt_with_poi restricted_stock_deferred\n",
    "    salary                     0.993311082       0.98788358            -0.007903563              -0.445034982\n",
    "    to_messages                0.033652765      -0.01527473             0.882062494              -0.004478446\n",
    "    deferral_payments          0.958108631       0.95003459             0.005958577              -0.430441448\n",
    "    total_payments             0.962046810       0.96539799             0.032152459              -0.378268396\n",
    "    exercised_stock_options    0.983374292       0.98615449            -0.029501077              -0.432672962\n",
    "    bonus                      1.000000000       0.98344674             0.047518123              -0.440520280\n",
    "    restricted_stock           0.983446742       1.00000000            -0.019283273              -0.456229181\n",
    "    shared_receipt_with_poi    0.047518123      -0.01928327             1.000000000               0.005202391\n",
    "    restricted_stock_deferred -0.440520280      -0.45622918             0.005202391               1.000000000\n",
    "    total_stock_value          0.986016441       0.99306005            -0.026169099              -0.440206357\n",
    "    expenses                   0.987001190       0.98111464            -0.023309401              -0.443636754\n",
    "    loan_advances              0.752378491       0.77737385             0.057610800              -0.317392139\n",
    "    from_messages              0.006055219      -0.01603798             0.302726689              -0.010899427\n",
    "    other                      0.959031981       0.97167348             0.003783105              -0.420779662\n",
    "    from_this_person_to_poi    0.042789182      -0.01394585             0.525601288              -0.008650658\n",
    "    poi                        0.023754969       0.01520883             0.243312982              -0.005362459\n",
    "    director_fees              0.947248521       0.94038245            -0.102634380              -0.343280346\n",
    "    deferred_income           -0.969017217      -0.95686502            -0.008038932               0.436273674\n",
    "    long_term_incentive        0.987034238       0.97952734            -0.005584562              -0.439291876\n",
    "    from_poi_to_this_person    0.054515307      -0.01897855             0.734200226              -0.022683017\n",
    "\n",
    "                              total_stock_value     expenses loan_advances from_messages        other\n",
    "    salary                           0.98948654  0.993987182    0.73611783  -0.007720450  0.963279325\n",
    "    to_messages                     -0.02468259 -0.019883533    0.04821607   0.508814271 -0.011148402\n",
    "    deferral_payments                0.95354812  0.956175331    0.69047507  -0.011847391  0.946820414\n",
    "    total_payments                   0.96821100  0.945323616    0.89569597  -0.016512929  0.982825157\n",
    "    exercised_stock_options          0.99879383  0.980173421    0.77539887  -0.024505437  0.966964245\n",
    "    bonus                            0.98601644  0.987001190    0.75237849   0.006055219  0.959031981\n",
    "    restricted_stock                 0.99306005  0.981114641    0.77737385  -0.016037984  0.971673480\n",
    "    shared_receipt_with_poi         -0.02616910 -0.023309401    0.05761080   0.302726689  0.003783105\n",
    "    restricted_stock_deferred       -0.44020636 -0.443636754   -0.31739214  -0.010899427 -0.420779662\n",
    "    total_stock_value                1.00000000  0.982885449    0.77921715  -0.022204355  0.971330083\n",
    "    expenses                         0.98288545  1.000000000    0.71983429  -0.004280533  0.951529277\n",
    "    loan_advances                    0.77921715  0.719834294    1.00000000  -0.028359278  0.842760505\n",
    "    from_messages                   -0.02220436 -0.004280533   -0.02835928   1.000000000 -0.036341757\n",
    "    other                            0.97133008  0.951529277    0.84276051  -0.036341757  1.000000000\n",
    "    from_this_person_to_poi         -0.02124827 -0.011225352   -0.02488482   0.609987734 -0.039366056\n",
    "    poi                              0.03446248 -0.009456427    0.13178914  -0.032633400  0.022232561\n",
    "    director_fees                    0.94486220  0.956347765    0.68503832  -0.040692094  0.912887195\n",
    "    deferred_income                 -0.96395674 -0.963304082   -0.69608443   0.016163693 -0.941804530\n",
    "    long_term_incentive              0.98346162  0.982047147    0.75204015  -0.010942170  0.966168888\n",
    "    from_poi_to_this_person         -0.01883314 -0.027190330    0.03963416   0.254959795  0.007797323\n",
    "\n",
    "                              from_this_person_to_poi           poi director_fees deferred_income long_term_incentiv\n",
    "    salary                               -0.006882893 -0.0006265269    0.95449450    -0.971051773         0.99017246\n",
    "    to_messages                           0.605984265  0.1112615893   -0.08794146     0.013093481        -0.01227079\n",
    "    deferral_payments                    -0.023737120 -0.0404085788    0.92184400    -0.968219094         0.95370716\n",
    "    total_payments                       -0.003703825  0.0497768025    0.91030549    -0.923116722         0.96040261\n",
    "    exercised_stock_options              -0.024442433  0.0403149911    0.94353303    -0.963598610         0.98139499\n",
    "    bonus                                 0.042789182  0.0237549686    0.94724852    -0.969017217         0.98703438\n",
    "    restricted_stock                     -0.013945854  0.0152088272    0.94038245    -0.956865016         0.97952342\n",
    "    shared_receipt_with_poi               0.525601288  0.2433129816   -0.10263438    -0.008038932        -0.00554562\n",
    "    restricted_stock_deferred            -0.008650658 -0.0053624590   -0.34328035     0.436273674        -0.43929186\n",
    "    total_stock_value                    -0.021248270  0.0344624846    0.94486220    -0.963956739         0.98346122\n",
    "    expenses                             -0.011225352 -0.0094564270    0.95634777    -0.963304082         0.98204147\n",
    "    loan_advances                        -0.024884820  0.1317891383    0.68503832    -0.696084428         0.75204013\n",
    "    from_messages                         0.609987734 -0.0326334002   -0.04069209     0.016163693        -0.01094270\n",
    "    other                                -0.039366056  0.0222325607    0.91288719    -0.941804530         0.96616888\n",
    "    from_this_person_to_poi               1.000000000  0.1310080926   -0.05022345     0.023262256         0.00146196\n",
    "    poi                                   0.131008093  1.0000000000   -0.06138801    -0.039544261         0.01288675\n",
    "    director_fees                        -0.050223454 -0.0613880127    1.00000000    -0.928889823         0.94455138\n",
    "    deferred_income                       0.023262256 -0.0395442615   -0.92888982     1.000000000        -0.96625050\n",
    "    long_term_incentive                   0.001461896  0.0128860748    0.94455154    -0.966250350         1.00000000\n",
    "    from_poi_to_this_person               0.498936149  0.1926209739   -0.08496750    -0.007899908         0.00283021\n",
    "\n",
    "                              from_poi_to_this_person\n",
    "    salary                               -0.006525242\n",
    "    to_messages                           0.619994085\n",
    "    deferral_payments                     0.018061379\n",
    "    total_payments                        0.029829644\n",
    "    exercised_stock_options              -0.019124514\n",
    "    bonus                                 0.054515307\n",
    "    restricted_stock                     -0.018978549\n",
    "    shared_receipt_with_poi               0.734200226\n",
    "    restricted_stock_deferred            -0.022683017\n",
    "    total_stock_value                    -0.018833141\n",
    "    expenses                             -0.027190330\n",
    "    loan_advances                         0.039634159\n",
    "    from_messages                         0.254959795\n",
    "    other                                 0.007797323\n",
    "    from_this_person_to_poi               0.498936149\n",
    "    poi                                   0.192620974\n",
    "    director_fees                        -0.084967503\n",
    "    deferred_income                      -0.007899908\n",
    "    long_term_incentive                   0.002830121\n",
    "    from_poi_to_this_person               1.000000000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Feature selection using three methods\n",
    "\n",
    "a. FeatureRFE() - recursive feature elimination using a random forests classfier performs a random forest classification on the data set using all the combinations of features and finds out over successive interations which ones are the best for predicition of the labels (targets. We restrict that the number of features  to be used in the combination to 4 and the output shown below suggest which can be used and which should not be used \n",
    "\n",
    "        featureRFEout = { 'salary': False, 'to_messages': False, \\\n",
    "        'deferral_payments': False, 'total_payments': False, 'loan_advances': False, \\\n",
    "    'bonus': True, 'restricted_stock_deferred': False, 'total_stock_value': True, \\\n",
    "    'shared_receipt_with_poi': False, 'long_term_incentive': False, \\\n",
    "    'exercised_stock_options': False, 'from_messages': False, 'other': True, \\\n",
    "    'from_poi_to_this_person': False, 'from_this_person_to_poi': False, \\\n",
    "    'deferred_income': False, 'expenses': True, 'restricted_stock': False, \\\n",
    "    'director_fees': False }\n",
    "\n",
    "we should use bonus, total_stock_value, expenses from here, it also flags \"other\" as true, but we can ignore this for now to see if other feature selection processes recommend it.\n",
    "\n",
    "\n",
    "  \n",
    "b. FeatureETC() - is an extra method learnt for feature extraction using bagged trees, called the extra trees classifier - the results from feature RFE selection are as below,\n",
    "\n",
    "    featureETCoutput = {'salary': 0.041632257710185139, 'to_messages': 0.039859107742246484,\\\n",
    "                    'deferral_payments': 0.024074150367185947, \\\n",
    "                    'total_payments': 0.064555518959854619, \\\n",
    "                    'loan_advances': 0.0093116015112734048, \\\n",
    "                    'bonus': 0.073052292449863596, \\\n",
    "                    'restricted_stock_deferred': 0.0042245370370370353,\\\n",
    "                    'total_stock_value': 0.09369028839725424, \\\n",
    "                    'shared_receipt_with_poi': 0.071123487226284629, \\\n",
    "                    'long_term_incentive': 0.04046480320342271, \\\n",
    "                    'exercised_stock_options': 0.1129150917901071, \\\n",
    "                    'from_messages': 0.024095798427395669, \\\n",
    "                    'other': 0.054538316103403574, \\\n",
    "                    'from_poi_to_this_person': 0.036628178381556319, \\\n",
    "                    'from_this_person_to_poi': 0.052257500165677206, \\\n",
    "                    'deferred_income': 0.10772890822303453, \\\n",
    "                    'expenses': 0.10845624961908869,\\\n",
    "                    'restricted_stock': 0.038109225603169372, \\\n",
    "                    'director_fees': 0.0032826870819597218}\\\n",
    "                   \n",
    "                   \n",
    "here features with values close to 1. should be used like : exercised stock value, total_stock_value, expenses since total and exercised stocks are highly correlated (from the correlation table) it makese sense to use only one of these features. total_stock_values and expenses. \n",
    "      \n",
    "c. Correlations - table helped select the most valuable features with lower values of cross-correlation like  expenses, total_stock_value, bonus and salary.\n",
    "    \n",
    "The results from ETC and the RFE feature selection process recommended using features in combination : \n",
    "a. salary, b. bonus, c. total_stock_value, d. expenses \n",
    "\n",
    "\n",
    "d. A new function was created in tester.py called featureNoSelect which used RFE and the scoring as precision to select the optimal number of features using all the data.\n",
    "\n",
    "    featureNoSelect(features4, labels4)\n",
    "    Optimal number of features : 6\n",
    "    \n",
    "e. Using the combination of the new features, the feature list now becomes.  \n",
    "\n",
    "     features_list2 = ['poi','salary', 'total_stock_value', 'expenses', 'bonus',  'relative_importance'] \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Removing outliers\n",
    "First the task was to view all the outliers\n",
    "\n",
    "This was done using the following :\n",
    "\n",
    "    a. plotSalaryStock(data1) - plotting salary Vs Total stock value\n",
    "    \n",
    "    b. plotSalaryExpense(data1) - plotting salary Vs receipt with poi\n",
    "    \n",
    "    c. plotStockExpense(data1) - plotting stock vs receipt with poi\n",
    "    \n",
    "    d. plotSalaryBonus(data1) - plotting salary vs bonus\n",
    "\n",
    "\n",
    "Outliers were removed using three functions:\n",
    "\n",
    "\n",
    "    a. Salary outliers removed :Salary outliers removed : ['TOTAL'] \n",
    "\n",
    "    b. Total stock value outliers removed : ['BELFER ROBERT', 'TOTAL'] \n",
    "\n",
    "    c. Bonus outliers removed : ['TOTAL'] \n",
    "\n",
    "    d. Expenses outliers removed  ['TOTAL'] \n",
    "    \n",
    " \n",
    "The plots were replotted after removal of outliers using the plotting functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creating new feature(s)\n",
    "\n",
    "\n",
    "Building feature for relative importance\n",
    "Total number of \"to emails\" to this person - shared_with_poi - sent_by_poi_to_this_person.\n",
    "The lower this number greater the relative importance since it means that most of the communication to this person involved conversation with a poi or in the same conversation with a poi. The number of emails from other people to this person was low.  \n",
    "\n",
    "This was done in the newFeature function.\n",
    "\n",
    "A function was created to extract the people who could have this feature due to condition of having values of \"to emails\", \"shared_receiept_with_poi\" and \"sent_by_poi_to_person\" feature.\n",
    "The people who had this feature, added to the data set were the follows. \n",
    "\n",
    "\n",
    "    ['METTS MARK', 'CORDES WILLIAM R', 'HANNON KEVIN P', 'MEYER ROCKFORD G', 'MCMAHON JEFFREY', 'HORTON STANLEY C', 'PIPER GREGORY F', 'HUMPHREY GENE E', 'UMANOFF ADAM S', 'BLACHMAN JEREMY M', 'SUNDE MARTIN', 'GIBBS DANA R', 'COLWELL WESLEY', 'MULLER MARK S', 'JACKSON CHARLENE R', 'WALLS JR ROBERT H', 'KITCHEN LOUISE', 'SHANKMAN JEFFREY A', 'BERGSIEKER RICHARD P', 'BIBI PHILIPPE A', 'RIEKER PAULA H', 'BECK SALLY W', 'HAUG DAVID L', 'HICKERSON GARY J', 'LEWIS RICHARD', 'HAYES ROBERT E', 'MCCARTY DANNY J', 'LEFF DANIEL P', 'LAVORATO JOHN J', 'POWERS WILLIAM', 'BANNANTINE JAMES M', 'SHAPIRO RICHARD S', 'SHERRIFF JOHN R', 'SHELBY REX', 'DEFFNER JOSEPH M', 'WHALLEY LAWRENCE G', 'MCCONNELL MICHAEL S', 'PIRO JIM', 'DELAINEY DAVID W', 'LAY KENNETH L', 'OLSON CINDY K', 'MCDONALD REBECCA', 'MCCLELLAN GEORGE', 'HAEDICKE MARK E', 'BOWEN JR RAYMOND M', 'FITZGERALD JAY L', 'MORAN MICHAEL P', 'REDMOND BRIAN L', 'BELDEN TIMOTHY N', 'DURAN WILLIAM D', 'THORN TERENCE H', 'FOY JOE', 'CALGER CHRISTOPHER F', 'RICE KENNETH D', 'KAMINSKI WINCENTY J', 'COX DAVID', 'SKILLING JEFFREY K', 'SHERRICK JEFFREY B', 'PICKERING MARK R', 'KEAN STEVEN J', 'FOWLER PEGGY', 'WASAFF GEORGE', 'ALLEN PHILLIP K', 'SHARP VICTORIA T', 'BROWN MICHAEL', 'HUGHES JAMES A', 'BHATNAGAR SANJAY', 'CARTER REBECCA C', 'BUCHANAN HAROLD G', 'MURRAY JULIA H', 'GARLAND C KEVIN', 'DODSON KEITH', 'DIETRICH JANET R', 'DERRICK JR. JAMES V', 'FREVERT MARK A', 'HAYSLETT RODERICK J', 'FALLON JAMES B', 'KOENIG MARK E', 'IZZO LAWRENCE L', 'TILNEY ELIZABETH A', 'MARTIN AMANDA K', 'BUY RICHARD B', 'CAUSEY RICHARD A', 'TAYLOR MITCHELL S', 'DONAHUE JR JEFFREY M', 'GLISAN JR BEN F']\n",
    "\n",
    "\n",
    "The values of this parameter was added to the final data set with the key \"relative_importance\". This was also used in the final analysis and predictions.\n",
    "\n",
    "### A new features list was created that included this parameter for predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extracting data for local testing and validation.\n",
    "\n",
    "\n",
    "Features were now extracted and stored for local testing using the featureFormat(), here validation comes in.\n",
    "\n",
    "#### In validation training and testing sets are constructed just by splitting some original dataset into more than one part. But the evaluations obtained in this case tend to reflect the particular way the data are divided up. The solution is to use statistical sampling to get a more accurate measurments or in this case stratified shuffle sampling (SSS).\n",
    "\n",
    "This gives equal opportunity for testing and training data to have an equal ratio of POIs to non-POIs are present in the training and test set. \n",
    "\n",
    "The training sets are then used to construct classifiers and then run them on the testing data to predicts its classes. By using SSS we have greatly decreased the chances of having results that reflect the way in which the data is divided. If we train and test a classifier using the same data, then accuracy will be very high and the algorithm will perform poorly on newly unseen data.\n",
    "\n",
    "Here 5 splits of training and testing data are done with shuffling of the indices so that this object is a merge of StratifiedKFold and ShuffleSplit, which returns stratified randomized folds. The folds are made by preserving the percentage of samples for each class.\n",
    "A sample split is seen as below. 3 such randomized splits are done.\n",
    "\n",
    "    TRAIN: [ 50  87  11  99 136  72  14  15  71 104  24 111  27   8 102  32 128  21\n",
    "           1  20  69  30  48  41  81 112  86  76   2  29 108  56  12  64  88 130\n",
    "          84  53  22   3  33   9  49 127  60  70   4 103 115  89 116  57 124  36\n",
    "           113 110  59 121  79  18  39   6 107  17  97 137 106  66  75] \n",
    "           \n",
    "    TEST: [119   7 114  40  61 131  90  63  73  74 105 101 120  44  68  43 123  85\n",
    "          93 133  80  34   0  96 100 134  94  91  54  98  52  95 118 135  45  92\n",
    "          65  16  62 129  35 126  23  31  51  28  78  26  55 117   5  10  19  13\n",
    "         109  25  47  82  83 122  42  67 132 125  38  46  58  77  37] \n",
    "\n",
    "Here feature scaling was not used since most of the features were found to be in the same range of values 10^6 - 10^7.\n",
    "\n",
    "It is usually necessary when a large variance is applied is seen in the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Trying variety of classifiers\n",
    "\n",
    "Many classifiers were tried on each of the splitted data sets (each one giving various values of prec and acc): \n",
    "\n",
    "    a. classifyNB() - Naive bayes classifier\n",
    "    b. classifyRF() - Random Forests classifier\n",
    "    c. classifyAB() - Adaboost classifier\n",
    "    d. classifyDT() - Decision tree classifier\n",
    "    e. classifySVM() - Support vector machine classifier\n",
    "    \n",
    "#### 5.1. The following were the average results on the precision and accuracy of each classifier using the original feature list:\n",
    "    \n",
    "    features_list = ['poi','salary', 'total_stock_value', 'expenses', 'bonus'] \n",
    " \n",
    "    average accuracy NB :  0.855882352941\n",
    "    precision accuracy NB :  0.479047619048\n",
    "    \n",
    "    average accuracy RF :  0.882352941176\n",
    "    precision accuracy RF :  0.733333333333\n",
    "    \n",
    "    average accuracy AB :  0.858823529412\n",
    "    precision accuracy AB :  0.42\n",
    "    \n",
    "    average accuracy DT :  0.841176470588\n",
    "    precision accuracy DT :  0.41617965368\n",
    "\n",
    "       \n",
    "#### 5.2. The following were the average results on the precision and accuracy of each classifier using the new feature added:\n",
    "    \n",
    "    features_list2 = ['poi','salary', 'total_stock_value', 'expenses', 'bonus',  'relative_importance'] \n",
    "\n",
    " \n",
    "    average accuracy NB :  0.866666666667\n",
    "    precision accuracy NB :  0.566666666667\n",
    "    \n",
    "    average accuracy RF :  0.872463768116\n",
    "    precision accuracy RF :  0.583333333333\n",
    "    \n",
    "    average accuracy AB :  0.849275362319\n",
    "    precision accuracy AB :  0.406666666667\n",
    "    \n",
    "    average accuracy DT :  0.828985507246\n",
    "    precision accuracy DT :  0.384790764791\n",
    " \n",
    "The predictions with the new feature added have resulted in slightly better accuracy in all cases except DT. \n",
    "Let's see what the tester.py says.\n",
    "                \n",
    "Stay tuned, in the next section for what tuning actually means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Tuning the classifier \n",
    "\n",
    "\n",
    "\n",
    "Decision tree classifier was tuned and used for predicitions using the following parameters:\n",
    "\n",
    "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "             max_features=None, max_leaf_nodes=None,\n",
    "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "             presort=False, random_state=None, splitter='best')\n",
    "             \n",
    "             Accuracy: 0.80386       Precision: 0.34262      Recall: 0.40600 F1: 0.37162     F2: 0.39151\n",
    "            Total predictions: 14000        True positives:  812    False positives: 1558   False negatives: 1188   \n",
    "            True negatives: 10442\n",
    "             \n",
    "Here we can tune the following parameters : criterion which is the function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain.  max_features is the number of features to consider when looking for the best split:\n",
    "    If int, then consider max_features features at each split.\n",
    "    If float, then max_features is a percentage and int(max_features * n_features) features are considered at each \n",
    "    split.\n",
    "    If “auto”, then max_features=sqrt(n_features).\n",
    "    If “sqrt”, then max_features=sqrt(n_features).\n",
    "    If “log2”, then max_features=log2(n_features).\n",
    "    If None, then max_features=n_features.\n",
    "    \n",
    "etc. The idea being that parameter tuning is required to tweak different aspects of the classification algorithm, usually most algorithms have paramters in them called alpha, gamma etc which basically control the fitting process, the \"flexibility\" or \"variablity\" of the fit. For eg in Support vector classifiers, the kernel functions used for the fitting can be \"linear\", \"poly\", \"sigmoid\", \"rbf\" etc and this can be chosen by the user. Another paramter is the  gamma which is the Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. All these control the performance of the algorithm and its usability on test data predictions/ classification. \n",
    "\n",
    "\n",
    "The other classifier that was tried was the NB classifier and it gave better results on precision and recall.\n",
    "\n",
    "    GaussianNB(priors=None)\n",
    "        Accuracy: 0.85629       Precision: 0.49612      Recall: 0.38400 F1: 0.43292     F2: 0.40218\n",
    "        Total predictions: 14000        True positives:  768    False positives:  780   False negatives: 1232   True \n",
    "        negatives: 11220\n",
    "        \n",
    "Here we see the Precision and recall are better.\n",
    "\n",
    "Precision is the ratio of true positives / all positives . Here it means that we can predict true positives well but we also predict slighty more than half of the required as false positives. This means the algorithm is very aggressive on positive predictions and needs to be more sensitive about the classification as positives. \n",
    "\n",
    "Recall is the ratio of true positive / (true positive + false negatives). Here it means that we are predicting some false negatives. But it is not too high as we are good with predicting true negatives.  Tuning should be done for better sensitivity towards prediciting true outcomes by using a more conservative algorithm.  \n",
    "\n",
    "Accuracy is the true positive + true negative / all predicitions. Which is how good the algorithm is overall in classifiying the data. In this scenario on the validation steps our accuracy is quite high 86% on the NB classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Dumping the classifier, dataset, and features_list \n",
    "\n",
    "The classifier were dumped using the following:\n",
    "\n",
    "clf = classifyNB()\n",
    "my_dataset = my_dataset\n",
    "features_list = features_list\n",
    "\n",
    "#### 7.1 and the tester.py was used which gave values of both precision and recall > 0.3 for new feature set:\n",
    "\n",
    "    features_list2 = ['poi','salary', 'total_stock_value', 'expenses', 'bonus',  'relative_importance'] \n",
    "    \n",
    "        GaussianNB(priors=None)\n",
    "        Accuracy: 0.85629       Precision: 0.49612      Recall: 0.38400 F1: 0.43292     F2: 0.40218\n",
    "        Total predictions: 14000        True positives:  768    False positives:  780   False negatives: 1232   True negatives: 11220\n",
    "\n",
    "\n",
    "#### 7.2 for the original feature set:\n",
    "\n",
    "     features_list = ['poi','salary', 'total_stock_value', 'expenses', 'bonus'] \n",
    "     \n",
    "         GaussianNB(priors=None)\n",
    "        Accuracy: 0.84179       Precision: 0.42272      Recall: 0.29400 F1: 0.34680     F2: 0.31307\n",
    "        Total predictions: 14000        True positives:  588    False positives:  803   False negatives: 1412   True negatives: 11197\n",
    "        \n",
    "### Hence the new engineered feature has really made a difference!\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
